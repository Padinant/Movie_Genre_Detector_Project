{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chloe-nguyenminh/Movie_Genre_Detector_Project/blob/main/Copy_of_Movie_Detector_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qf8pl6Jvc3qA"
      },
      "outputs": [],
      "source": [
        "# Movie Detector Final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlamqI-Xc86c"
      },
      "outputs": [],
      "source": [
        "# Set up: Importing numpy, pandas, etc.\n",
        "import ast\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from numpy.random import RandomState\n",
        "from tensorflow.keras import datasets, layers, models, Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization, Conv2D, MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Movie_Poster_Project/Dataset_clean/data_no_dupl_with_existing_posters.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jvnge5DjdHKp"
      },
      "outputs": [],
      "source": [
        "# resizing\n",
        "img_width = 253\n",
        "img_height = 253\n",
        "\n",
        "image_dir = '/content/drive/MyDrive/Movie_Poster_Project/Dataset_clean/train'\n",
        "image_dir2 = '/content/drive/MyDrive/Movie_Poster_Project/Dataset_clean/test'\n",
        "\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    directory=image_dir,\n",
        "    image_size=(img_width, img_height),\n",
        "    shuffle=True,\n",
        "    batch_size=32,\n",
        "    label_mode='int'\n",
        ")\n",
        "\n",
        "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    directory=image_dir2,\n",
        "    image_size=(img_width, img_height),\n",
        "    shuffle=True,\n",
        "    batch_size=32,\n",
        ")\n",
        "\n",
        "print(train_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_dataset.class_names"
      ],
      "metadata": {
        "id": "KhKFpirwDwzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "JfhJAYN5DtdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Added layer of augmentation\n",
        "data_augmentation = tf.keras.Sequential([layers.RandomFlip(\"horizontal\", input_shape=(img_height, img_width, 3)), \n",
        "                                      layers.RandomRotation(0.1), layers.RandomZoom(0.1)])"
      ],
      "metadata": {
        "id": "1_mrkJwmMmBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(class_names)\n",
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(64, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "epochs=10\n",
        "history = model.fit(\n",
        "  train_dataset,\n",
        "  batch_size=32,\n",
        "  epochs=epochs,\n",
        "  validation_data=test_dataset,\n",
        ")"
      ],
      "metadata": {
        "id": "fbsbXdnCMhFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytxJvWLZ2Z99"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkxvWRvwx0wY2sRi/qtvRk",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}